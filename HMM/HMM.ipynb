{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6e112fe",
   "metadata": {},
   "source": [
    "## Hidden Markov Model\n",
    "HMM is priobabilistic model used for NLP task, that describe relationship between sequence of observation and sequence of hidden state. It is used various application such as speech recognition, POS tagging, NER .It is extenson of Markov model \n",
    "\n",
    "HNN consist of two types of states\n",
    "- hidden states(latent states)\n",
    "- observation state(output states)\n",
    "\n",
    "Key Component\n",
    " - **Transition Probabilities**: These represent the probabilities of transitioning from one hidden state to another. The transition probabilities form the transition matrix, where each element represents the probability of transitioning from one hidden state to another.\n",
    " \n",
    "- **Emission Probabilities**: These represent the probabilities of emitting an observable state from each hidden state. The emission probabilities form the emission matrix, where each element represents the probability of observing a specific output state given a hidden state.\n",
    "\n",
    "- **Initial State Probabilities**: These represent the probabilities of starting the sequence from a specific hidden state. The initial state probabilities represent the probability distribution of the first hidden state.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86d1459",
   "metadata": {},
   "source": [
    "HMMs are trained using the **Viterbi algorithm** or the **Baum-Welch** algorithm to estimate the model parameters (transition probabilities, emission probabilities, and initial state probabilities) from the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64847d6",
   "metadata": {},
   "source": [
    "## Example:  Hidden Markov Models\n",
    "https://www.youtube.com/watch?v=fX5bYmnHqqE\n",
    "\n",
    "Problem statement - Teacher wear red/Green/blue shirt \n",
    "\n",
    "Assumption - A teacher happy(H) or sad(S) based of previous day assumption\n",
    "\n",
    "**Transition Matrix**\n",
    "\n",
    "|  | $$H_t$$ | $$S_t$$ |\n",
    "|---|---|---|\n",
    "| $$H_{t-1}$$ | 0.7 | 0.3 |\n",
    "| $$S_{t-1}$$ | 0.5 | 0.5 |\n",
    "\n",
    "If teacher is happy pervious day then, probability of teacher is happy today is 0.7<br>\n",
    "If teacher is happy pervious day then, probability of teacher is sad today is 0.5\n",
    "\n",
    "**Emission Matrix**\n",
    "\n",
    "|  | R | G | B |\n",
    "|---|---|---|---|\n",
    "| H | 0.8 | 0.1 | 0.1 |\n",
    "| S | 0.2 | 0.3 | 0.5 |\n",
    "\n",
    "If teacher is happy then, probability of teacher wear red shirt is 0.8<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0ee437",
   "metadata": {},
   "source": [
    "## Example: Part-of-Speech Tagging with Hidden Markov Models\n",
    "POS tagging is the process of assigning a part-of-speech label to each word in a sentence.\n",
    "\n",
    "**Hidden States** - POS tag\n",
    "\n",
    "##### Transition Probabilities:\n",
    "P(Noun | Noun) = 0.5<br>\n",
    "P(Verb | Verb) = 0.4<br>\n",
    "P(Preposition | Preposition) = 0.3<br>\n",
    "....\n",
    "\n",
    "##### Emission Probabilities\n",
    "P(\"I\" | PRON) = 0.2<br>\n",
    "P(\"work\" | Verb) = 0.5<br>\n",
    "....\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189e4b6e",
   "metadata": {},
   "source": [
    "## Viterbi algorithm\n",
    "Viterbi algorithm is a dynamic programming algorithm for finding the most likely sequence of hidden states in a hidden Markov model (HMM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23de2b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from hmmlearn import hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60e99673",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = ['H','S']\n",
    "observation_state = ['R','G','B']\n",
    "n_state = len(state)\n",
    "n_observation = len(observation_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd69242d",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_probabilty = np.array([0.6,0.4])\n",
    "transition_matrix = np.array([[0.7,0.3],[0.5,0.5]])\n",
    "emission_matrix = np.array([[0.8,0.1,0.1],[0.2,0.3,0.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfac4f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = hmm.CategoricalHMM(n_components=n_state)\n",
    "model.startprob_ = state_probabilty\n",
    "model.transmat_ = transition_matrix\n",
    "model.emissionprob_ = emission_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1323832d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation_seq = np.array([0,1,1,2,0]).reshape(-1,1)\n",
    "# predict the most likely sequence of hidden states\n",
    "model.predict(observation_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a585618",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
