{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO3lHEe5tucoaGl1M5uIQfL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ujjalkumarmaity/NLP/blob/main/Huggingface-transformer-reinforcement-learning/Supervised_fine_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAD7XVmTuDiL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "FOXMimW_wpd1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c51db77-8d97-45a9-bd2c-d71e930ff0b8_2292x1234.png'>"
      ],
      "metadata": {
        "id": "wJ_out_Iwp21"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- One of the most widely-used forms of fine-tuning for LLMs within recent AI research is supervised fine-tuning (SFT).\n",
        "- This approach curates a dataset of high-quality LLM outputs over which the model is directly fine-tuned using a standard language modeling objective\n",
        "- SFT is simple/cheap to use and a useful tool for aligning language models,"
      ],
      "metadata": {
        "id": "vm28VK1zw_E9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training LLMs\n",
        "\n",
        "The training process for language models typically proceeds in three phases.\n",
        "\n",
        "<img src='https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb9d0144-3952-42db-8382-8e2eb37d917e_1670x640.png'>\n",
        "\n",
        "- First, we pretrain the language model, which is (by far) the most computationally-expensive step of training\n",
        "- supervised fine-tuning (SFT)\n",
        "- reinforcement learning from human feedback (RLHF)\n",
        "\n",
        "<img src='https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F680ffa81-7b96-474f-832b-4be758e8d2e6_1176x638.png'>"
      ],
      "metadata": {
        "id": "gjQcf1fnx6eF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9v1tHGMEykm9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cLbZN90p1dS0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is SFT?"
      ],
      "metadata": {
        "id": "3SevGGdQy9RE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "training data for SFT\n",
        "<img src='https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8fbd7695-b32e-49a5-9d8b-dac180c767a1_1274x676.png'>"
      ],
      "metadata": {
        "id": "S0mTvJ5r0uWE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SFT vs Pre-Training**\n",
        "\n",
        "The main difference arises in the data that is used. During pretraining, we use a massive corpus of raw textual data to train the model. In contrast, SFT uses a supervised dataset of high-quality LLM outputs.\n",
        "\n",
        "During each training iteration, we sample several examples, then fine-tune the model on this data using a next token prediction objective"
      ],
      "metadata": {
        "id": "Lo1t8AfV0uii"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Where did this come from?\n",
        "\n",
        "The three-step alignment process—including both SFT and RLHF—was originally proposed by InstructGPT"
      ],
      "metadata": {
        "id": "mhBAgL3T0up7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SqzkhbPsbGow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BqgUdCpBbGlj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "anaRnsaHbGig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4TC9vh74bGWh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}