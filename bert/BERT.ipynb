{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ujjalkumarmaity/NLP/blob/main/bert/BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03bd9ceb",
      "metadata": {
        "id": "03bd9ceb"
      },
      "source": [
        "## BERT (Bidirectional Encoder Representations from Transformers)\n",
        "-\n",
        "\n",
        "\n",
        "\n",
        "#### BERT NLP Application\n",
        "- Google Search\n",
        "- Sentiment Analysis\n",
        "- Language Translation\n",
        "- Text Summarization\n",
        "- Question Answering\n",
        "- Highlighting paragraphs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre-trained bert model\n",
        "- **BERT-base**: This is the base version of BERT with 12 transformer layers, 768 hidden units, and 12 self-attention heads.\n",
        "\n",
        "- **BERT-large**: BERT-large is a larger version of BERT with 24 transformer layers, 1024 hidden units, and 16 self-attention heads\n",
        "\n",
        "- **BERT-cased**: BERT-cased retains the casing information of the original text during pre-training. This can be useful for tasks where capitalization plays a significant role, such as named entity recognition.\n",
        "\n",
        "- **BERT-uncased**: BERT-uncased converts all text to lowercase during pre-training. It is suitable when the case information is less important for the specific NLP task.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "h6B5P47kzS4u"
      },
      "id": "h6B5P47kzS4u"
    },
    {
      "cell_type": "markdown",
      "id": "917731b0",
      "metadata": {
        "id": "917731b0"
      },
      "source": [
        "### Reference\n",
        "http://jalammar.github.io/illustrated-bert/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ff118b6",
      "metadata": {
        "id": "7ff118b6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentiment analysis using BERT"
      ],
      "metadata": {
        "id": "geBKyXKhu604"
      },
      "id": "geBKyXKhu604"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "kmBmYOpdvaZB"
      },
      "id": "kmBmYOpdvaZB",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c4969c0a",
      "metadata": {
        "id": "c4969c0a"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "from transformers import BertModel, BertTokenizer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import pandas as pd,numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    torch.device('cuda')\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    torch.device('cpu')\n",
        "    device = 'cpu'"
      ],
      "metadata": {
        "id": "22YEzuaHYcmt"
      },
      "id": "22YEzuaHYcmt",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2a4d152c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "2a4d152c",
        "outputId": "95629ff0-9fe3-4cc0-b0b5-3c851aa2cb98"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             content  score  sentiment\n",
              "0                      I cannot open the app anymore      1          0\n",
              "1  I have been begging for a refund from this app...      1          0\n",
              "2  Very costly for the premium version (approx In...      1          0\n",
              "3  Used to keep me organized, but all the 2020 UP...      1          0\n",
              "4                                Dan Birthday Oct 28      1          0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2daf0613-8f46-4461-8112-015443e8031c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>score</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I cannot open the app anymore</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I have been begging for a refund from this app...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Very costly for the premium version (approx In...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Used to keep me organized, but all the 2020 UP...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dan Birthday Oct 28</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2daf0613-8f46-4461-8112-015443e8031c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2daf0613-8f46-4461-8112-015443e8031c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2daf0613-8f46-4461-8112-015443e8031c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/ujjalkumarmaity/NLP/main/bert/reviews.csv',on_bad_lines='skip')\n",
        "df = df[['content','score']]\n",
        "def convert_sentiment(x):\n",
        "    if x<=2:\n",
        "        return 0\n",
        "    elif x==3:\n",
        "        return 1\n",
        "    else:\n",
        "        return 2\n",
        "df['sentiment'] = df.score.apply(convert_sentiment)\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.score.value_counts().plot(kind='bar')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "nuc330gnwF-J",
        "outputId": "16344820-f95e-4526-c23e-87c18cad42dd"
      },
      "id": "nuc330gnwF-J",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[['content','sentiment']]"
      ],
      "metadata": {
        "id": "Ums6h1S_iQ-J"
      },
      "id": "Ums6h1S_iQ-J",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# max word of content\n",
        "df.content.str.split().str.len().max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnFuWyoQz-9p",
        "outputId": "4c350e44-07e8-4c9d-dcfc-a6bdee3420bc"
      },
      "id": "cnFuWyoQz-9p",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "723"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocess Data"
      ],
      "metadata": {
        "id": "tuIHTS5QBRqN"
      },
      "id": "tuIHTS5QBRqN"
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
      ],
      "metadata": {
        "id": "OkRkH0AAAmck"
      },
      "id": "OkRkH0AAAmck",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.tokenize(\"let define the metrics you\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--_1TrjmH1aR",
        "outputId": "c55be3f1-cb3d-49aa-8bb7-1fad38909110"
      },
      "id": "--_1TrjmH1aR",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['let', 'define', 'the', 'metric', '##s', 'you']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct a BERT tokenizer\n",
        "tokenizer('let define the metrics you')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Z3fjYKICZMU",
        "outputId": "0de53f40-809a-4116-80eb-18c93484a634"
      },
      "id": "_Z3fjYKICZMU",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 1519, 9410, 1103, 12676, 1116, 1128, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converts a string to a sequence of ids (integer), using the tokenizer and vocabulary.\n",
        "tokenizer.encode('let define the metrics you')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUXGeogWA4gU",
        "outputId": "5e17af8c-7cbc-42c0-a1c7-c159b43c651a"
      },
      "id": "cUXGeogWA4gU",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[101, 1519, 9410, 1103, 12676, 1116, 1128, 102]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.encode_plus(\"let define the metrics you\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VmOpjQ0ZpfI",
        "outputId": "79d41f4e-0533-40e6-f1b8-cd4ac9ecc675"
      },
      "id": "5VmOpjQ0ZpfI",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 1519, 9410, 1103, 12676, 1116, 1128, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare torch dataset"
      ],
      "metadata": {
        "id": "npMjkYRfXUSX"
      },
      "id": "npMjkYRfXUSX"
    },
    {
      "cell_type": "code",
      "source": [
        "class ReviewData(Dataset):\n",
        "    def __init__(self,tokenizer,review,label,max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.review = review\n",
        "        self.label = label\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.review)\n",
        "    def __getitem__(self,ind):\n",
        "        review = self.review[ind]\n",
        "        label = self.label[ind]\n",
        "        embed = self.tokenizer.encode_plus(review,\n",
        "                                           add_special_tokens=True,\n",
        "                                           max_length = self.max_len,\n",
        "                                           return_attention_mask = True,\n",
        "                                           return_token_type_ids=False,\n",
        "                                           pad_to_max_length = True,\n",
        "                                           return_tensors = 'pt')\n",
        "        return {\n",
        "            'review' : review,\n",
        "            'input_ids' : embed['input_ids'].flatten(),\n",
        "            'attention_mask':embed['attention_mask'].flatten(),\n",
        "            'label' : torch.tensor(label,dtype = torch.long)\n",
        "        }"
      ],
      "metadata": {
        "id": "gLJBjn3WA8Ft"
      },
      "id": "gLJBjn3WA8Ft",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews = df.content.values\n",
        "senttiment = df.sentiment.values\n",
        "rd = ReviewData(tokenizer,reviews,senttiment,512)"
      ],
      "metadata": {
        "id": "hF2nOMQabthc"
      },
      "id": "hF2nOMQabthc",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('review text',rd[5]['review'])\n",
        "print('input_ids shape',rd[5]['input_ids'].shape)\n",
        "print('attention_mask shape',rd[5]['attention_mask'].shape)\n",
        "print(rd[5]['label'])\n"
      ],
      "metadata": {
        "id": "2qwVqAEYbuDk",
        "outputId": "ff223ff2-d13f-4ae5-84a0-0c599a9bc6e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "2qwVqAEYbuDk",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "review text It has changed how I viewed my different lists. Now they are all jumbled together and I can't find what I need.\n",
            "input_ids shape torch.Size([512])\n",
            "attention_mask shape torch.Size([512])\n",
            "tensor(0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split Data**"
      ],
      "metadata": {
        "id": "oYUUnjj0h-Sa"
      },
      "id": "oYUUnjj0h-Sa"
    },
    {
      "cell_type": "code",
      "source": [
        "train,test = train_test_split(df,test_size=0.3,random_state = 10)\n",
        "test,val = train_test_split(test,test_size=0.4,random_state = 10)"
      ],
      "metadata": {
        "id": "yHmAJBfHeGNr"
      },
      "id": "yHmAJBfHeGNr",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create Pytorch DataLoader**"
      ],
      "metadata": {
        "id": "0VpBNh-zjBqT"
      },
      "id": "0VpBNh-zjBqT"
    },
    {
      "cell_type": "code",
      "source": [
        "def cerate_dataloader(df,tokenizer,max_len,batch_size):\n",
        "    reviews = df.content.values\n",
        "    senttiment = df.sentiment.values\n",
        "    rd = ReviewData(tokenizer,reviews,senttiment,max_len)\n",
        "    return DataLoader(rd,batch_size = batch_size)\n"
      ],
      "metadata": {
        "id": "I4FJb-4sjAbQ"
      },
      "id": "I4FJb-4sjAbQ",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "max_len = 512\n",
        "train_dataloader = cerate_dataloader(train,tokenizer,max_len,batch_size)\n",
        "val_dataloader = cerate_dataloader(val,tokenizer,max_len,batch_size)\n",
        "test_dataloader = cerate_dataloader(test,tokenizer,max_len,batch_size)"
      ],
      "metadata": {
        "id": "lcCI-Wb9krMy"
      },
      "id": "lcCI-Wb9krMy",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model creation"
      ],
      "metadata": {
        "id": "L_-2f-X30n5p"
      },
      "id": "L_-2f-X30n5p"
    },
    {
      "cell_type": "code",
      "source": [
        "bert = BertModel.from_pretrained('bert-base-cased')\n",
        "bert.config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVOSG5vi0bWf",
        "outputId": "22c8e8b5-8df8-4f0c-c65f-4de5909081d8"
      },
      "id": "BVOSG5vi0bWf",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertConfig {\n",
              "  \"_name_or_path\": \"bert-base-cased\",\n",
              "  \"architectures\": [\n",
              "    \"BertForMaskedLM\"\n",
              "  ],\n",
              "  \"attention_probs_dropout_prob\": 0.1,\n",
              "  \"classifier_dropout\": null,\n",
              "  \"gradient_checkpointing\": false,\n",
              "  \"hidden_act\": \"gelu\",\n",
              "  \"hidden_dropout_prob\": 0.1,\n",
              "  \"hidden_size\": 768,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"intermediate_size\": 3072,\n",
              "  \"layer_norm_eps\": 1e-12,\n",
              "  \"max_position_embeddings\": 512,\n",
              "  \"model_type\": \"bert\",\n",
              "  \"num_attention_heads\": 12,\n",
              "  \"num_hidden_layers\": 12,\n",
              "  \"pad_token_id\": 0,\n",
              "  \"position_embedding_type\": \"absolute\",\n",
              "  \"transformers_version\": \"4.30.2\",\n",
              "  \"type_vocab_size\": 2,\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 28996\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentModel(nn.Module):\n",
        "    def __init__(self,n_class):\n",
        "        super(SentimentModel,self).__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.output = nn.Linear(self.bert.config.to_dict()['hidden_size'],n_class)\n",
        "\n",
        "    def forward(self,input_ids,attention_mask):\n",
        "        _,pooled_out = self.bert(input_ids = input_ids,attention_mask = attention_mask,return_dict=False)\n",
        "        out = self.dropout(pooled_out)\n",
        "        return self.output(out)\n",
        ""
      ],
      "metadata": {
        "id": "9WpBX26N0g4P"
      },
      "id": "9WpBX26N0g4P",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimizer and Learning Rate Scheduler"
      ],
      "metadata": {
        "id": "OVwLc0nc7-wQ"
      },
      "id": "OVwLc0nc7-wQ"
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamW,get_linear_schedule_with_warmup\n",
        "epoch = 10\n",
        "n_class = 3\n",
        "learnng_rate = 5e-5\n",
        "model = SentimentModel(3)\n",
        "model.to(device)\n",
        "# create optimizer\n",
        "optimizer = AdamW(model.parameters(),lr = learnng_rate)\n",
        "total_train_step = len(train_dataloader) * epoch\n",
        "\n",
        "# create learning rate schedular\n",
        "schedular = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps = 0,\n",
        "    num_training_steps = total_train_step\n",
        ")\n",
        "loss_fun = nn.CrossEntropyLoss().to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVcg993V0jTP",
        "outputId": "2edd1831-b4e0-4975-a1c3-6dadb7615aa6"
      },
      "id": "jVcg993V0jTP",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Loop"
      ],
      "metadata": {
        "id": "kMksuQ3x_Z5W"
      },
      "id": "kMksuQ3x_Z5W"
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model,train_dataloader,optimizer,schedular,n_examples):\n",
        "    torch.cuda.empty_cache()\n",
        "    correct_classify = 0\n",
        "    losses = []\n",
        "    model = model.train()\n",
        "    for data in train_dataloader:\n",
        "        input_ids = data['input_ids'].to(device)\n",
        "        attention_mask = data['attention_mask'].to(device)\n",
        "        actual_label = data['label'].to(device)\n",
        "        output = model(input_ids,attention_mask)\n",
        "        _,pred = torch.max(output,axis=1)\n",
        "        loss = loss_fun(output,actual_label)\n",
        "        correct_classify += torch.sum(pred==actual_label)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "        schedular.step()\n",
        "        optimizer.zero_grad()\n",
        "    return correct_classify.double() / n_examples, np.mean(losses)"
      ],
      "metadata": {
        "id": "K9XyaEqv9LGl"
      },
      "id": "K9XyaEqv9LGl",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_model(model,val_dataloader,optimizer,schedular,n_examples):\n",
        "    torch.cuda.empty_cache()\n",
        "    correct_classify = 0\n",
        "    losses = []\n",
        "    with torch.no_grad():\n",
        "        for data in val_dataloader:\n",
        "            input_ids = data['input_ids'].to(device)\n",
        "            attention_mask = data['attention_mask'].to(device)\n",
        "            actual_label = data['label'].to(device)\n",
        "            output = model(input_ids,attention_mask)\n",
        "            _,pred = torch.max(output,axis=1)\n",
        "            loss = loss_fun(output,actual_label)\n",
        "            correct_classify += torch.sum(pred==actual_label)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "    return correct_classify.double() / n_examples, np.mean(losses)"
      ],
      "metadata": {
        "id": "9R_D983a9y89"
      },
      "id": "9R_D983a9y89",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "history = defaultdict(list)\n",
        "for epoch in range(2):\n",
        "    print(\"Epoch \",epoch+1)\n",
        "    print('='*10)\n",
        "    train_acc,train_loss = train(model,train_dataloader,optimizer,schedular,len(train_dataloader))\n",
        "    val_acc,val_loss = train(model,val_dataloader,optimizer,schedular,len(val_dataloader))\n",
        "    history['train_accuracy'].append(train_acc)\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['val_accuracy'].append(val_acc)\n",
        "    history['val_loss'].append(val_loss)\n",
        "    print(\"train loss: \",train_loss,'    train accuracy',train_acc )\n",
        "    print(\"validation loss: \",val_loss,'    validation accuracy',val_acc )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfY62kieFiyq",
        "outputId": "15f3ea03-02db-440e-dc4d-b989d04e574b"
      },
      "id": "ZfY62kieFiyq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  1\n",
            "==========\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r-_w1rcrJJwY"
      },
      "id": "r-_w1rcrJJwY",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8RatVVJTNgnX"
      },
      "id": "8RatVVJTNgnX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wmbZZh7qUdV8"
      },
      "id": "wmbZZh7qUdV8",
      "execution_count": 25,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}