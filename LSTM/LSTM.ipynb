{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "310a4fa5",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"LSTM (Long Short-Term Memory)\"\n",
    "date: \"5/30/2023\"\n",
    "categories:\n",
    "  - LSTM\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec48e701",
   "metadata": {},
   "source": [
    "## LSTM (Long Short-Term Memory)\n",
    "- LSTM is a type of RNN architecture that is widely used for sequnce modeling task \n",
    "- LSTM overcome RNN limitation(vanising gradient) by introducing a memory cell and three gating mechanisms.\n",
    "- Memory cell in LSTM allows to store and access information over long sequence\n",
    "- LSTMs use a series of gates which control how the information in a sequence of data comes into, is stored in and leaves the network. they are -\n",
    "    - forgot gate\n",
    "    - input gate\n",
    "    - output gate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c12d074",
   "metadata": {},
   "source": [
    "### Application\n",
    "- **NLP task**- named entity recognition, sentiment analysis, machine translation etc.\n",
    "- **Speech Recognition** - automatic speech recognition, speech-to-text conversion etc.\n",
    "- **Time Series Analysis and Forecasting** - stock market prediction, weather forecasting etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0c93db",
   "metadata": {},
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d1c539",
   "metadata": {},
   "source": [
    "#### Forget gate layer\n",
    "First step in the process is Forgot gate. This gate telling  the LSTM how much information keep from previous state. Output of this gate is between 0 and 1. Output of this forgot gate multiply with previous LSTM output.\n",
    "<img height = 300 width=600 src='http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-f.png'><br>\n",
    "output of forgot gate is 0 implies `->` Forget all previous memory<br>\n",
    "output of forgot gate is 1 implies `->` Keep all previous memory<br>\n",
    "output of forgot gate is 0.5 implies `->` Keep some of previous memory<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12101afc",
   "metadata": {},
   "source": [
    "#### Input gate layer\n",
    "Goal of this step is how much information take from new memory. This sigmoid layer is call input gate decides which values we’ll update.\n",
    "\n",
    "output of forgot gate is 0 implies `->` Didn't take anything from generated memory<br>\n",
    "output of forgot gate is 1 implies `->` Take anything from generated memory<br>\n",
    "output of forgot gate is 0.5 implies `->` Take partially from generated memory<br>\n",
    "<img height = 300 width=600 src='http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-i.png'>\n",
    "\n",
    "The new **memory network** is a tanh activated neural network which has learned how to combine the previous hidden state and new input data to generate a ‘new memory update vector’. This vector essentially contains information from the new input data given the context from the previous hidden state\n",
    "\n",
    "<img height = 300 width=600 src='http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-C.png'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4907add",
   "metadata": {},
   "source": [
    "#### Output Gate\n",
    "The output gate, deciding the new hidden state.\n",
    " - First, we run a sigmoid layer which decides what parts of the cell state we’re going to output.\n",
    " - Then, we put the cell state through tanh and multiply it by the output of the sigmoid gate, so that we only output the parts we decided to.\n",
    "\n",
    "\n",
    "<img height = 300 width=600 src='http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-o.png'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03ba70a",
   "metadata": {},
   "source": [
    "### Drawbacks LSTM\n",
    "- Computational Complexity\n",
    "- Training Time\n",
    "- Difficulty in Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf74324",
   "metadata": {},
   "source": [
    "### Reference\n",
    "- http://colah.github.io/posts/2015-08-Understanding-LSTMs/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f93ba8",
   "metadata": {},
   "source": [
    "# Implementation of LSTM from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75c03a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ujjal\\anaconda3\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transform\n",
    "from torch.functional import F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0763438e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST('/',train=True,download=True,transform = transform.ToTensor())\n",
    "test_data = datasets.MNIST('/',train=False,download=True,transform = transform.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e3a6cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataset():\n",
    "    def __init__(self,data) -> None:\n",
    "        self.data = data\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self,ind):\n",
    "        x,target = self.data[ind]\n",
    "        # print(x.size()) # torch.Size([1, 28, 28])\n",
    "        x = x.view((1,28*28))\n",
    "        # print(x.size()) # torch.Size([1, 784])\n",
    "        return {'input':x,\n",
    "                'label':target}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddcbeb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "train_dataloader = DataLoader(MNISTDataset(train_data),batch_size=BATCH_SIZE,shuffle=True)\n",
    "test_dataloader = DataLoader(MNISTDataset(train_data),batch_size=BATCH_SIZE,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e06ad60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.functional import F\n",
    "class LSTMCell(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,bias=False) -> None:\n",
    "        super().__init__()\n",
    "        self.input_size = input_size # input = (batch_size,input_size)\n",
    "        self.hidden_size = hidden_size # h\n",
    "        self.linear1 = nn.Linear(self.input_size,4*self.hidden_size,bias=bias)\n",
    "        self.linear2 = nn.Linear(self.hidden_size,4*self.hidden_size,bias=bias)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        std = 1.0 / np.sqrt(self.hidden_size)\n",
    "        for w in self.parameters():\n",
    "            w.data.uniform_(-std, std)\n",
    "\n",
    "    def forward(self,input,h_x=None):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            input = (batch_size,input_size)\n",
    "            h_x (_type_): previous hidden state output\n",
    "        \"\"\"\n",
    "\n",
    "        if h_x ==None:\n",
    "            # Hidden state output shape = (batch_size, hidden_units)\n",
    "            # batch_size refers to the number of samples or sequences processed in each batch.\n",
    "            # hidden_units represents the number of hidden units or neurons in the LSTM layer.\n",
    "            hx = Variable(input.new_zeros(input.shape[0],self.hidden_size))\n",
    "            h_x = (hx,hx)\n",
    "        h_t1,c_t1 = h_x # \n",
    "   \n",
    "        # print(\"h_t1\",h_t1.size())\n",
    "        # print(self.linear1(input).size() , self.linear2(h_t1).size())\n",
    "        gate = self.linear1(input) + self.linear2(h_t1)\n",
    "        # print(\"gate\",gate.size())\n",
    "        f_t_,i_t_,c_t_,o_t_ = torch.chunk(gate,4,dim=1)\n",
    "        \n",
    "        \n",
    "        f_t = F.sigmoid(f_t_)\n",
    "        i_t = F.sigmoid(i_t_)\n",
    "        c_t = F.tanh(c_t_)\n",
    "        o_t = F.sigmoid(o_t_)\n",
    "        \n",
    "        c_t = f_t*c_t1 + i_t*c_t\n",
    "        h_t = o_t * F.tanh(c_t)\n",
    "\n",
    "        return (h_t,c_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e046db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ujjal\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "C:\\Users\\ujjal\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    }
   ],
   "source": [
    "lstm = LSTMCell(28*28,4)\n",
    "MNISTDataset(train_data)[0]['input'].shape\n",
    "h_t,c_t = lstm(MNISTDataset(train_data)[0]['input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ede7f6d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 4]), torch.Size([1, 4]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_t.shape,c_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e687078",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (1258053652.py, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[8], line 17\u001b[1;36m\u001b[0m\n\u001b[1;33m    \u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self,input_size,num_layers,hidden_size,bias,output_size) -> None:\n",
    "        super(LSTMCell,self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bias = bias\n",
    "        self.output_size = output_size\n",
    "        self.lstm_cell_list = nn.ModuleList()\n",
    "        \n",
    "        self.lstm_cell_list.append(LSTMCell(self.input_size,self.hidden_size,self.bias))\n",
    "        for _ in range(1,self.num_layers):\n",
    "            self.lstm_cell_list.append(LSTMCell(self.input_size,self.hidden_size,self.bias))\n",
    "        sself.sc = nn.Linear(self.hidden_size,self.output_size)\n",
    "    \n",
    "    def forward(self,x,hx=None):\n",
    "        if hx==None:\n",
    "            h0 = Variable(self.num_layers,input.new_zeros(input.shape[0],self.hidden_size))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d59579cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = LSTMCell(28*28,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0d3956e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 784])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNISTDataset(train_data)[0]['input'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42e08550",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.ModuleList?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3b8f38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e8f0f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1865dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c7c95d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d250210f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "64028950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0275, 0.8263, 0.1286, 0.2876, 0.1218, 0.6262, 0.9347, 0.8457, 0.3715,\n",
       "         0.5222]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc3526d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b940c94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://github.com/hadi-gharibi/pytorch-lstm/blob/master/lstm.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
